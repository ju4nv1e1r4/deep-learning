{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/medidas.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura</th>\n",
       "      <th>Peso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187</td>\n",
       "      <td>109.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177</td>\n",
       "      <td>91.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180</td>\n",
       "      <td>88.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Altura    Peso\n",
       "0     187  109.72\n",
       "1     177   91.09\n",
       "2     180   88.93"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.Altura.values\n",
    "y = df.Peso.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (100,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) (100,)\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape(-1, 1)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Puro\n",
    "\n",
    "*Para transformar o perceptron em um regressor, basta remover a função de ativação.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: 1024641.7518430601\n",
      "step 1000: 8173.51508088843\n",
      "step 2000: 3590.671800476251\n",
      "step 3000: 2790.716648439308\n",
      "step 4000: 2652.819219900905\n",
      "step 5000: 2629.7841589568757\n",
      "step 6000: 2626.2517504352213\n",
      "step 7000: 2625.849626271206\n",
      "step 8000: 2625.8711079824543\n",
      "step 9000: 2625.9136227218874\n",
      "step 10000: 2625.937363237822\n",
      "w: [np.float64(1.3697035107991162)]\n",
      "b: -157.8653723865976\n",
      "y_pred: [ 98.26918413  84.57214902  88.68125956  84.57214902  84.57214902\n",
      "  92.79037009  85.94185254  84.57214902  92.79037009  99.63888764\n",
      "  72.24481743  85.94185254  66.76600338  79.09333498  83.20244551\n",
      "  77.72363147  74.98422445  91.42066658  87.31155605  79.09333498\n",
      "  81.832742    73.61452094  92.79037009  62.65689285  84.57214902\n",
      "  54.43867179  76.35392796  95.52977711  96.89948062  64.02659636\n",
      "  77.72363147  83.20244551  84.57214902  72.24481743  88.68125956\n",
      "  94.1600736   62.65689285  69.50541041  99.63888764  87.31155605\n",
      "  80.46303849  74.98422445  88.68125956 103.74799818 107.85710871\n",
      "  83.20244551  80.46303849  76.35392796  80.46303849  98.26918413\n",
      "  46.22045072  64.02659636  55.8083753   40.74163668  50.32956125\n",
      "  69.50541041  76.35392796  64.02659636  72.24481743  53.06896828\n",
      "  68.1357069   58.54778232  64.02659636  59.91748583  53.06896828\n",
      "  83.20244551  66.76600338  53.06896828  62.65689285  62.65689285\n",
      "  59.91748583  73.61452094  51.69926477  47.59015423  87.31155605\n",
      "  65.39629987  84.57214902  74.98422445  66.76600338  72.24481743\n",
      "  55.8083753   65.39629987  73.61452094  85.94185254  65.39629987\n",
      "  57.17807881  64.02659636  62.65689285  61.28718934  55.8083753\n",
      "  44.85074721  61.28718934  64.02659636  59.91748583  74.98422445\n",
      "  69.50541041  68.1357069   59.91748583  59.91748583  70.87511392]\n"
     ]
    }
   ],
   "source": [
    "'''step 1: Inicializar pesos e bias'''\n",
    "\n",
    "D = x.shape[1]\n",
    "w = [2*random() - 1 for i in range(D)]\n",
    "b = 2*random() - 1\n",
    "\n",
    "''' step 2: Para cada amostra aleatória:\n",
    "    a) Calcular a saida;\n",
    "    b) Calcular o erro;\n",
    "    c) Atualizar os pesos;\n",
    "    d) Atualizar os bias.\n",
    "'''\n",
    "wl_rate = 1e-7\n",
    "bl_rate = 1e-2\n",
    "\n",
    "for step in range(10_001):\n",
    "    cost = 0\n",
    "    for xn, yn in zip(x, y):\n",
    "        y_pred = sum([xi*wi for xi, wi in zip(xn, w)]) + b\n",
    "        erro = yn - y_pred\n",
    "        w = [wi + wl_rate * erro * xi for xi, wi in zip(xn, w)]\n",
    "        b = b + bl_rate * erro\n",
    "        cost += erro**2\n",
    "    if step % 1000 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "\n",
    "print('w:', w)\n",
    "print('b:', b)\n",
    "print('y_pred: {0}'.format(np.dot(x, np.array(w))+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: 248964.2976349774\n",
      "step 1000: 3213.5094682473728\n",
      "step 2000: 2725.411570399813\n",
      "step 3000: 2641.786321687843\n",
      "step 4000: 2628.037407162114\n",
      "step 5000: 2626.0264626494964\n",
      "step 6000: 2625.8444971991808\n",
      "step 7000: 2625.8847011792955\n",
      "step 8000: 2625.9220998651044\n",
      "step 9000: 2625.9414089280567\n",
      "step 10000: 2625.9501484679945\n",
      "w: [1.36989521]\n",
      "b: -157.89739408616484\n",
      "y_pred: [ 98.27300984  84.57405776  88.68374339  84.57405776  84.57405776\n",
      "  92.79342901  85.94395297  84.57405776  92.79342901  99.64290505\n",
      "  72.24500089  85.94395297  66.76542005  79.09447693  83.20416255\n",
      "  77.72458172  74.9847913   91.4235338   87.31384818  79.09447693\n",
      "  81.83426734  73.6148961   92.79342901  62.65573443  84.57405776\n",
      "  54.43636318  76.35468651  95.53321943  96.90311463  64.02562964\n",
      "  77.72458172  83.20416255  84.57405776  72.24500089  88.68374339\n",
      "  94.16332422  62.65573443  69.50521047  99.64290505  87.31384818\n",
      "  80.46437214  74.9847913   88.68374339 103.75259067 107.8622763\n",
      "  83.20416255  80.46437214  76.35468651  80.46437214  98.27300984\n",
      "  46.21699193  64.02562964  55.80625839  40.7374111   50.32667756\n",
      "  69.50521047  76.35468651  64.02562964  72.24500089  53.06646797\n",
      "  68.13531526  58.54604881  64.02562964  59.91594401  53.06646797\n",
      "  83.20416255  66.76542005  53.06646797  62.65573443  62.65573443\n",
      "  59.91594401  73.6148961   51.69657276  47.58688714  87.31384818\n",
      "  65.39552485  84.57405776  74.9847913   66.76542005  72.24500089\n",
      "  55.80625839  65.39552485  73.6148961   85.94395297  65.39552485\n",
      "  57.1761536   64.02562964  62.65573443  61.28583922  55.80625839\n",
      "  44.84709672  61.28583922  64.02562964  59.91594401  74.9847913\n",
      "  69.50521047  68.13531526  59.91594401  59.91594401  70.87510568]\n"
     ]
    }
   ],
   "source": [
    "'''step 1: Inicializar pesos e bias'''\n",
    "D = x.shape[1]\n",
    "w = 2*np.random.random(size=D)-1\n",
    "b = 2*np.random.random()-1\n",
    "\n",
    "''' step 2: Para cada amostra aleatória:\n",
    "    a) Calcular a saida;\n",
    "    b) Calcular o erro;\n",
    "    c) Atualizar os pesos;\n",
    "    d) Atualizar os bias.\n",
    "'''\n",
    "wl_rate = 1e-7\n",
    "bl_rate = 1e-2\n",
    "\n",
    "for step in range(10_001):\n",
    "    cost = 0\n",
    "    for xn, yn in zip(x, y):\n",
    "        y_pred = np.dot(xn, w) + b\n",
    "        erro = yn - y_pred\n",
    "        w = w + wl_rate * np.dot(erro, xn)\n",
    "        b = b + bl_rate * erro\n",
    "        cost += erro**2\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "\n",
    "print('w:', w)\n",
    "print('b:', b)\n",
    "print('y_pred: {0}'.format(np.dot(x, np.array(w))+b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy com pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "minmax = MinMaxScaler(feature_range=(-1, 1))\n",
    "x = minmax.fit_transform(x.astype(np.float64))\n",
    "\n",
    "print(x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [33.60164767]\n",
      "b: 74.99636286981101\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x, y)\n",
    "\n",
    "print('w:', lr.coef_)\n",
    "print('b:', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: 529388.0315617786\n",
      "step 100: 3142.5059791454514\n",
      "step 200: 2623.8670783539824\n",
      "step 300: 2611.5458827247435\n",
      "step 400: 2611.2517999114534\n",
      "step 500: 2611.244575307423\n",
      "step 600: 2611.2443663425192\n",
      "step 700: 2611.2443556110484\n",
      "step 800: 2611.2443544671482\n",
      "step 900: 2611.24435430301\n",
      "step 1000: 2611.2443542779947\n",
      "w: [33.60180845]\n",
      "b: 74.9389642686916\n",
      "y_pred: [ 98.94025602  85.22523216  89.33973932  85.22523216  85.22523216\n",
      "  93.45424647  86.59673455  85.22523216  93.45424647 100.3117584\n",
      "  72.88171069  86.59673455  67.39570115  79.73922262  83.85372978\n",
      "  78.36772023  75.62471546  92.08274409  87.96823693  79.73922262\n",
      "  82.48222739  74.25321308  93.45424647  63.28119399  85.22523216\n",
      "  55.05217968  76.99621785  96.19725125  97.56875363  64.65269638\n",
      "  78.36772023  83.85372978  85.22523216  72.88171069  89.33973932\n",
      "  94.82574886  63.28119399  70.13870592 100.3117584   87.96823693\n",
      "  81.110725    75.62471546  89.33973932 104.42626556 108.54077272\n",
      "  83.85372978  81.110725    76.99621785  81.110725    98.94025602\n",
      "  46.82316536  64.65269638  56.42368206  41.33715582  50.93767252\n",
      "  70.13870592  76.99621785  64.65269638  72.88171069  53.68067729\n",
      "  68.76720353  59.16668683  64.65269638  60.53818922  53.68067729\n",
      "  83.85372978  67.39570115  53.68067729  63.28119399  63.28119399\n",
      "  60.53818922  74.25321308  52.30917491  48.19466775  87.96823693\n",
      "  66.02419876  85.22523216  75.62471546  67.39570115  72.88171069\n",
      "  56.42368206  66.02419876  74.25321308  86.59673455  66.02419876\n",
      "  57.79518445  64.65269638  63.28119399  61.90969161  56.42368206\n",
      "  45.45166298  61.90969161  64.65269638  60.53818922  75.62471546\n",
      "  70.13870592  68.76720353  60.53818922  60.53818922  71.5102083 ]\n"
     ]
    }
   ],
   "source": [
    "'''step 1: Inicializar pesos e bias'''\n",
    "D = x.shape[1]\n",
    "w = 2*np.random.random(size=D)-1\n",
    "b = 2*np.random.random()-1\n",
    "\n",
    "''' step 2: Para cada amostra aleatória:\n",
    "    a) Calcular a saida;\n",
    "    b) Calcular o erro;\n",
    "    c) Atualizar os pesos;\n",
    "    d) Atualizar os bias.\n",
    "'''\n",
    "learning_rate_np = 1e-3\n",
    "\n",
    "for step in range(1001):\n",
    "    cost = 0 # inicializando com um custo zero\n",
    "    for xn, yn in zip(x, y):\n",
    "        y_pred = np.dot(xn, w) + b\n",
    "        erro = yn - y_pred\n",
    "        w = w + learning_rate_np * np.dot(erro, xn)\n",
    "        b = b + learning_rate_np * erro\n",
    "        cost += erro**2 # calculando o custo\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "\n",
    "print('w:', w)\n",
    "print('b:', b)\n",
    "print('y_pred: {0}'.format(np.dot(x, np.array(w))+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prova1</th>\n",
       "      <th>prova2</th>\n",
       "      <th>prova3</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prova1  prova2  prova3  final\n",
       "0      73      80      75    152\n",
       "1      93      88      93    185\n",
       "2      89      91      90    180"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provas = pd.read_csv('../data/notas.csv')\n",
    "provas.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = provas.drop('final', axis=1).values\n",
    "y = provas['final'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3) (25,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "minmax = MinMaxScaler(feature_range=(-1, 1))\n",
    "x = minmax.fit_transform(x.astype(np.float64))\n",
    "\n",
    "print(x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [ 8.72048636 14.1054877  26.26749487]\n",
      "b: 150.65175754349872\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x, y)\n",
    "\n",
    "print('w:', lr.coef_)\n",
    "print('b:', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: 498630.08959754824\n",
      "step 500: 146.86000948261793\n",
      "step 1000: 146.15414080249343\n",
      "step 1500: 146.15066112265575\n",
      "step 2000: 146.15066878557883\n",
      "w: [ 8.72518951 14.1394923  26.32051346]\n",
      "b: 150.71119383290605\n",
      "y_pred: [152.67150063 185.2011281  181.89868545 199.89638911 139.20892486\n",
      " 103.66277966 150.32362133 112.81326781 174.66050556 164.57742324\n",
      " 143.46911243 142.27591007 186.6683133  152.46868054 151.30572548\n",
      " 189.25435652 143.54441423 182.01521915 177.4071795  158.42323263\n",
      " 176.68664103 174.76605466 167.78163742 150.69216867 191.32825299]\n"
     ]
    }
   ],
   "source": [
    "'''step 1: Inicializar pesos e bias'''\n",
    "D = x.shape[1]\n",
    "w = 2*np.random.random(size=D)-1\n",
    "b = 2*np.random.random()-1\n",
    "\n",
    "''' step 2: Para cada amostra aleatória:\n",
    "    a) Calcular a saida;\n",
    "    b) Calcular o erro;\n",
    "    c) Atualizar os pesos;\n",
    "    d) Atualizar os bias.\n",
    "'''\n",
    "learning_rate_np = 1e-2\n",
    "\n",
    "for step in range(2001):\n",
    "    cost = 0\n",
    "    for xn, yn in zip(x, y):\n",
    "        y_pred = np.dot(xn, w) + b\n",
    "        erro = yn - y_pred\n",
    "        w = w + learning_rate_np * np.dot(erro, xn)\n",
    "        b = b + learning_rate_np * erro\n",
    "        cost += erro**2\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print('step {0}: {1}'.format(step, cost))\n",
    "\n",
    "print('w:', w)\n",
    "print('b:', b)\n",
    "print('y_pred: {0}'.format(np.dot(x, np.array(w))+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
